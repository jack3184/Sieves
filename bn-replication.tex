\documentclass[11pt,letterpaper]{article}                  % Define document class

%! Mandatory packages
\usepackage[utf8]{inputenc}                                %! Character encoding
\usepackage[T1]{fontenc}                                   %! Font encoding
\usepackage[english]{babel}                                %! Language setting

% Set path
\newcommand{\path}{/Users/Attila/OneDrive - Duke University/texts/latex-sample/Preamble}

% Text packages
\input{"\path/packText.tex"}
\newcommand\citepos[1]{\citeauthor{#1}'s\ (\citeyear{#1})}
\onehalfspacing

% Figure/table packages
\input{"\path/packFigure.tex"}

% Math packages
\input{"\path/packMath.tex"}

% Graphics packages
\input{"\path/packGraph.tex"}

% Title
\title{\citet{Blomquist2002}: \\ ``Nonparametric Estimation with Nonlinear Budget Sets'' \\ \smallskip \Large{A Replication Study}}
\author{Jackson Bunting and Attila Gyetvai\footnote{Department of Economics, Duke University. Emails: \href{mailto:jackson.bunting@duke.edu}{jackson.bunting@duke.edu}, \href{mailto:attila.gyetvai@duke.edu}{attila.gyetvai@duke.edu}. All errors are ours.}}
\date{\today}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\section{Motivation}

Tax systems typically impose nonlinearities on taxpayers' budget sets, which posit an econometric challenge for the empirical economist.
Many scholars offered solutions to circumvent this challenge, usually at the expense of making restrictive parametric assumptions on functional forms.
We replicate a study which is free from such restrictions: the influential paper by \citet{Blomquist2002}.
Utilizing a sieve regression framework, their study offers an excellent alternative to maximum likelihood estimators reigning at that time.

To simplify their analysis, \citet{Blomquist2002} look at piecewise linear budget sets, and we follow their lead.
We argue that this simplification is not overly restrictive for at least two reasons.
First, tax policies and means-tested transfers often impose income progressivity through threshold rules for marginal tax rates.
Combined with fixed hourly wage rates, this results in continuous piecewise budget sets with kinks.
Second, even if budget sets are not linear anywhere, a piecewise defined first order polynomial is suitable for approximation.

Our replication study is structured the following way:
In Section \ref{sec:framework} we discuss the theoretical framework.
In Section \ref{sec:estimation} we review the estimation procedure.
In Section \ref{sec:ex1} we illustrate the framework and estimate labor supply using simulated budget set and hours data in a simple example.
Section \ref{sec:ex2} showcases how estimation breaks down when one of the identifying assumptions does not hold.
In Section \ref{sec:policy} we conduct a counterfactual policy analysis.
Finally Section \ref{sec:conclusion} concludes.


\section{Framework}
\label{sec:framework}

Following \citet{Blomquist2002}, we lay out the framework for estimating labor supply below.
Assume that individual $i$ maximizes her convex preferences over a convex budget set.
Her optimal choice of hours can be represented by the labor supply function
\begin{align*}
	h_i^* &\equiv \pi (y_i, w_i, v_i)
\end{align*}
where $y_i$ denotes nonlabor income, $w_i$ denotes the fixed hourly wage rate, and $v_i$ represents individual heterogeneity that is unobserved by the econometrician.
As \citet{Blomquist2002} warn, an important feature of this setup is that $\pi(\cdot)$ is not linear in $v_i$.
We explore the necessity of this assumption by relaxing it; as we demonstrate later, the estimation breaks down when hours are linear in this heterogeneity variable.

Given this underlying theoretical model, \citet{Blomquist2002} focus on estimating the expected hours function
\begin{align*}
	\E [h_i | x_i] = \bar{h}(x_i)
\end{align*}
where $x_i$ represents the budget set over which individual $i$ optimizes.
When the budget set is piecewise linear, it is fully characterized by the intercepts and slopes of the linear segments, and the discontinuity points.
That is, a piecewise linear budget set with $J$ kinks can be described by
\begin{align*}
	x_i = (J, \, y_{1i}, \ldots, y_{Ji}, \, w_{1i}, \ldots, w_{Ji}, \, \ell_{1}, \ldots, \ell_{J-1}).
\end{align*}
Note that $\ell_{j}$ does not have an $i$ subscript.
This signals our implicit assumption that the locations of the discontinuity points are identical across individuals---a universal tax schedule is a suitable example.

\citet{Blomquist2002} show the following identification result:
Define the following functions:
\begin{align*}
	\bar{\pi} (y_i, w_i) &\equiv \int \pi(y_i, w_i, v_i) g(v_i) \, d v_i \qquad \text{and} \\
	\mu(y_i, w_i, \ell_i) &\equiv \int_{-\infty}^{\pi^{-1}(y_i, w_i, \ell_i)} \left[ \pi (y_i, w_i, v_i) - \ell_i \right] g(v_i) \, d v_i.
\end{align*}
Then if for all $J$ and $j = 1, \ldots, J$, (i) $\int \abs{\pi (y_j, w_j, v)} \, g(v) d(v) < \infty$, (ii) $\pi(y_j, w_j, v)$ is strictly increasing in $v$ on its support, and (iii) $\Pr (h=0 | x) = 0$, then the expected hours function can be written as
\begin{align*}
	\bar{h} (x) = \bar{\pi} (y_J, w_J) + \sum_{j=1}^{J-1} \left[ \mu(y_j, w_j, \ell_j) - \mu(y_{j+1}, w_{j+1}, \ell_j) \right].
\end{align*}
That is, expected hours can be additively decomposed over the linear segments representing the budget set.
We exploit this structure in our simulation.


\section{Estimation}
\label{sec:estimation}

Given the above framework, we now turn to estimation.
Expected hours can be estimated by running the sieve regression
\begin{align*}
	\hat{h}(x) &= p^K (x)' \hat{\beta} = p^K (x)' (P' P)^- P' h
\end{align*}
where $p^K (x)$ are $K$ functions that impose the additivity and equality constraints of the expected hours function $\bar{h} (x)$, $P$ is the matrix of these $K$ functions for all sampled individuals, and $(\cdot)^-$ denotes the usual generalized inverse transformation.
Following \citet{Blomquist2002}, we focus on power series approximations of the following form:
\begin{align*}
	p^K (x)' &= \begin{pmatrix}
		\left[ y_J^{p(k)} w_J^{q(k)} \right] ' \\
		\left[ \sum_{j=1}^{J-1} \left( \ell_j^{m(k)} y_j^{p(k)} w_j^{q(k)} - \ell_j^{m(k)} y_{j+1}^{p(k)} w_{j+1}^{q(k)} \right) \right]'
	\end{pmatrix}.
\end{align*}
Not surprisingly, the first row approximates $\bar{\pi} (y_J, w_J)$ whereas the second row is an approximation for $\sum_{j=1}^{J-1} [\mu(y_j, w_j, \ell_j) - \mu(y_{j+1}, w_{j+1}, \ell_j)]$.

\subsection{Generating data}
Since the paper is based on real data, which we do not have, it is necessary to create our own data.
We suppose that an individual $i$ is endowed with $y_i$ nonlabor income and 1 unit of time, which she can divide between work $h_i$ and leisure $1-h_i$.
Therefore she can spend up to $y_i + w_i h_i$ where $w_i$ is her wage rate.
Assume for the moment that her budget set is linear; we introduce nonlinearities in a moment.

Suppose that $i$'s preferences towards consumption $c_i$ and work $h_i$ can be represented by an isoelastic utility function; consequently the optimization problem she faces is 
\begin{align*}
	\max_{c_i, h_i} \enskip \frac{c_i^{1-\alpha} + (1-h_i)^{1-\alpha}}{1-\alpha} \qquad \text{s.t.} \enskip c_i \leq y_i v_i + w_i h_i
\end{align*}
where $v_i$ is a variable not observed by the econometrician.
That is, we regard $v_i$ as the measurement error in nonlabor income.
We assume that $v_i$ is drawn from a uniform distribution on the unit interval.
The resulting labor supply function is
\begin{align*}
	h_i^* &\equiv \pi (y_i, w_i, v_i) = \frac{w_i^{1/\alpha} - y_i v_i}{w_i^{1/\alpha} + w_i}.\footnotemark
\end{align*}
\footnotetext{Calculations can be found in Appendix \ref{app:iso}.}
To ensure that Condition (iii) for identification---zero probability of choosing zero hours---holds, we simulate $w$ and $y$ such that $\frac{w_i^{1/\alpha}}{y_i} > v_i$.
Since we assume that $v_i \sim U[0, 1]$, this essentially means that we restrict $w_i^{1/\alpha} > y_i$.\footnote{For the sake of generality, our accompanying code does consider the possibility of having a corner solution. However, we generate data such that this never occurs.}

Once the data is generated, the estimation procedure is easy to implement.
Two complications arise, though: (1) how to optimally choose the number of approximating terms $K$, and (2) in what order to include basis functions.

\subsection{Choosing $K$}

We follow \citepos{Blomquist2002} lead in making an optimal choice of $K$.
We implement a leave-one-out cross validation procedure.
In a nutshell, we choose the value of $K$ which minimizes the asymptotic mean squared error.
Technically we minimize the scale-normalized sum of squared one-step ahead forecast errors from predictions for $i$ using all observations but the $i$th.

A final remark on the optimal choice of $K$: on top of choosing one $K$, the econometrician needs to also set a maximum number of possible terms to consider.
We construct a large number of basis functions, thus theoretically we can choose from a wide range for $K$.
This, however, is a computationally burdensome exercise.\footnote{Out of curiosity, we once let the procedure choose $K$ optimally using the whole sieve space. Allowing up to 150 terms, the procedure ran for 45 minutes on a laptop with a quad-core Intel i7 processor.}
Since we found that the typical $K$ is below 10, we only consider 20 as the maximum number of terms.


\subsection{Constructing the basis}

We encountered three issues constructing a sieve space using the power series form.
The basic idea was to increase the degree of the power series approximation (recall that the approximation is a sum of two power series), by adding individual terms as $K$ increases.

The first issue is that there are multiple terms of the same degree, so there is no natural way to add terms.
For example, $x^2y^3$ and $x^4y^1$ are both degree 5, so when it comes to adding an extra degree 5 term, which should be added?
We just picked arbitrarily, as it is reflected in our results below.

The second issue regards linear dependence.
Quite often additional columns of the basis matrix were linear dependent with existing columns.
Our solution to this was to exclude the ``higher'' order linearly dependent columns.
(Strictly speaking, we constructed the basis by adding columns only if the additional column did not belong to the existing column space.)

The last issue is about numerical constraints.
We found that, due to the large powers being taken, the determinant of the square matrix generated by the basis matrix was very large.
We believe this made matrix inversion numerically imprecise.
However, this issue is only severe when the number of terms becomes large (approximately 25).



\subsection{Results}
\label{sec:ex1}

With optimal K, our model matches the data well: (The red line is the known expected labour supply function. The green
line is observed hours worked, and the blue line is our fitted model.)
 The estimation performs less well
around the non-smooth parts of the hours distribution---in our DGP,
these are due to bunching about the kink in the budget constraint
\begin{figure}[H]
	\centering
	\caption{Estimation results}
	\label{fig:est1}
	\includegraphics[scale=0.6]{fig_iso.pdf}
\end{figure}



\textbf{Jackson: I would shift the following section to an appendix, and you could signpost
  it in the `Generating Data' section}
\section{Another example}
\label{sec:ex2}

\begin{align*}
	\max_{c_i, h_i} \enskip c_i^{1-v_i} (1-h_i)^{v_i} \qquad \text{s.t.} \enskip c_i \leq y_i + w_i h_i
\end{align*}
where $v_i$ is an unknown scalar specific to $i$.
We assume that $v_i$ is drawn from a uniform distribution on $[0, \tfrac{1}{2}]$.
We need a tighter-than-unit interval to satisfy Condition (iii), nonzero hours choice.
The resulting labor supply function is
\begin{align*}
	h^*_i &\equiv \pi (y_i, w_i, v_i) = 1 - \frac{(1-v_i) y_i}{w_i}.\footnotemark
\end{align*}
\footnotetext{Calculations can be found in Appendix \ref{app:CD}.}

As reflected in the example, this doesn't really work.
Linearity!!



\section{Policy simulation}
\label{sec:policy}

Following Sections 3.4 and 5 in \citet{Blomquist2002}, we estimate the percent change in average labor supply from shifting budget sets.
We assume a minimum wage equal to $\tfrac{4}{10}$ of the mean wage is introduced:
\begin{align*}
  w_a = \max\left\{\tfrac{4}{10} \mathrm{E}[w_b], w_b\right\}
\end{align*}
where, as in \citet{Blomquist2002}, subscripts $a$ and $b$ refer to after and before the policy change.
We replicate Table I from Section 5.3:

\input {table1} \mbox{} \\

As the first row of \citepos{Blomquist2002} table, the regression in our first row has regressors $(1,y_j,w_j)$.
Working down the rows, additional terms are added to the basis.
Entries with two digits indicate terms $y_j^{\text{digit }1}w_j^{\text{digit }2}$ in the power series, and three digits indicate $(y_{j}^{\text{digit }1}w_j^{\text{digit }2} -
y_{j+1}^{\text{digit }1}w_{j+1}^{\text{digit }2})l_j^{\text{digit }3}$ as in Equations (3.2)-(3.4) of the original paper.

The estimator $M$ can be computed in a simpler way, but we have used the formulas provided by the paper.
Standard errors are computed similarly. 
Notice, Monte Carlo simulations are unnecessary for this replication,
since there the standard errors are known in closed form.
Compared to B\&N, our results are less robust to the choice of basis function but, plainly, there are so many differences between our analyses that comparisons are not clarifying.

We decided not do include the elasticity functional $E$, since it would be very tedious to take derivatives of the basis function.

\section{Conclusion}
\label{sec:conclusion}
\begin{itemize}
\item Estimation approximates simulated data well
\item However, policy sims sensitive to choice of basis
\end{itemize}




\bibliographystyle{apalike}
\bibliography{project}

\appendix

\section{Derivation of labor supply functions}

\subsection{Isoelastic utility}
\label{app:iso}

The maximization problem can be equivalently written as
\begin{align*}
	&\max_{h_i} \enskip \frac{(y_i v_i + w_i h_i)^{1-\alpha} + (1-h_i)^{1-\alpha}}{1-\alpha}.
	\intertext{The first-order condition is}
	0 &= (y_i v_i + w_i h_i^*)^{1-\alpha} \cdot w_i + (1-h_i^*)^{1-\alpha} \cdot (-1).
	\intertext{Rearranging yields}
	h_i^* &\equiv \pi (y_i, w_i, v_i) = \frac{w_i^{1/\alpha} - y_i v_i}{w_i^{1/\alpha} + w_i}.
	\intertext{We rule out corner solutions, and thus fulfill the identifying assumption that $\Pr (h=0 |x) = 0$ by ensuring that the numerator is positive.}
\end{align*}
We get $\bar{\pi}_i (y_i, w_i)$ by integrating $v_i$ out:
\begin{align*}
	\bar{\pi}_i (y_i, w_i) &= \int_0^1 \frac{w_i^{1/\alpha} - y_i v_i}{w_i^{1/\alpha} + w_i} \, d v_i = \left[ \frac{w_i^{1/\alpha} v_i}{w_i^{1/\alpha} + w_i} - \frac{y_i v_i^2}{2 \left( w_i^{1/\alpha} + w_i \right) } \right]_{v_i=0}^1 = \frac{1}{w_i^{1/\alpha} + w_i} \left( w_i^{1/\alpha} - \frac{y_i}{2} \right).
\end{align*}
Furthermore, we calculate the inverse of $\pi$ w.r.t $v_i$ as follows:
\begin{align*}
	\ell_i &= \frac{w_i^{1/\alpha} - y_i v_i}{w_i^{1/\alpha} + w_i} \\
	(w_i^{1/\alpha} + w_i) \ell_i &= w_i^{1/\alpha} - y_i v_i \\
	y_i v_i &= w_i - w_i \ell_i = w_i^{1/\alpha} - (w_i^{1/\alpha} + w_i) \ell_i \\
	v_i &= \frac{w_i^{1/\alpha} - (w_i^{1/\alpha} + w_i) \ell_i}{y_i} \equiv \pi^{-1} (y_i, w_i, \ell_i)
\end{align*}
Finally, we derive $\mu (y_i, w_i, \ell_i)$ as
\begin{align*}
	\mu (y_i, w_i, \ell_i) &= \int_0^{\frac{w_i^{1/\alpha} - (w_i^{1/\alpha} + w_i) \ell_i}{y_i}} \left[ \frac{w_i^{1/\alpha} - y_i v_i}{w_i^{1/\alpha} + w_i} - \ell_i \right] \, dv_i \\
	&= \left[ \frac{1}{w_i^{1/\alpha} + w_i} \left( w_i^{1/\alpha} v_i - \frac{y_i v_i^2}{2} \right) - \ell_i v_i \right]_{v_i=0}^{\frac{w_i^{1/\alpha} - (w_i^{1/\alpha} + w_i) \ell_i}{y_i}} \\
	&= \left( \frac{w_i^{1/\alpha}}{w_i^{1/\alpha} + w_i} - \ell_i \right) \frac{w_i^{1/\alpha} - (w_i^{1/\alpha} + w_i) \ell_i}{y_i} - \frac{\left[ w_i^{1/\alpha} - (w_i^{1/\alpha} + w_i) \ell_i \right]^2}{2 y_i} \\
	&= \frac{\left[ w_i^{1/\alpha} - (w_i^{1/\alpha} + w_i) \ell_i \right]^2}{(w_i^{1/\alpha} + w_i) y_i} - \frac{\left[ w_i^{1/\alpha} - (w_i^{1/\alpha} + w_i) \ell_i \right]^2}{2 y_i}
\end{align*}

\subsection{Cobb-Douglas utility}
\label{app:CD}

The maximization problem can be equivalently written as
\begin{align*}
	&\max_{h_i} \enskip (y_i + w_i h_i)^{1-v_i} (1-h_i)^{v_i}.
	\intertext{The first-order condition is}
	0 &= (1-v_i) (y_i + w_i h_i^*)^{-v_i} w_i (1-h_i^*)^{v_i} + v_i (y_i + w_i h_i^*)^{1-v_i} (1-h_i^*)^{v_i-1} \cdot (-1) \\
	  &= (1-v_i) w_i (1-h_i^*) - v_i (y_i + w_i h_i^*) \\
	  &= (1-v_i) w_i - (1-v_i) w_i h_i^* - v_i y_i - v_i w_i h_i^* \\
	  &= (1-v_i) w_i - w_i h_i^* - v_i y_i.
	\intertext{Rearranging yields}
	h_i^* &\equiv \pi (y_i, w_i, v_i) = 1 - v_i - \frac{v_i y_i}{w_i}.
\end{align*}
We get $\bar{\pi}_i (y_i, w_i)$ by integrating $v_i$ out:
\begin{align*}
	\bar{\pi}_i (y_i, w_i) &= \int_0^{\frac{1}{2}} \left[ 1 - v_i - \frac{v_i y_i}{w_i} \right] \cdot 2 \, d v_i = 2 \left[ v_i - \frac{v_i^2}{2} - \frac{v_i^2 y_i}{2 w_i} \right]_{v_i=0}^{\frac{1}{2}} = \frac{3}{4} - \frac{y_i}{4 w_i}.
	\intertext{Furthermore, we calculate the inverse of $\pi$ w.r.t $v_i$ as follows:}
	\ell_i &= 1 - v_i - \frac{v_i y_i}{w_i} \\
	w_i \ell_i &= w_i - v_i w_i - v_i y_i = w_i - v_i (w_i + y_i) \\
	v_i (w_i + y_i) &= w_i - w_i \ell_i = w_i (1-\ell_i) \\
	v_i &= \frac{w_i (1-\ell_i)}{w_i + y_i} \equiv \pi^{-1} (y_i, w_i, \ell_i)
\end{align*}
Finally, we derive $\mu (y_i, w_i, \ell_i)$ as
\begin{align*}
	\mu (y_i, w_i, \ell_i) &= \int_0^{\min \left\lbrace \frac{1}{2}, \frac{w_i (1-\ell_i)}{w_i + y_i} \right\rbrace} \left[ 1 - v_i - \frac{v_i y_i}{w_i} - \ell_i \right] \cdot 2 \, d v_i \\
	&= 2 \cdot \left[ v_i - \frac{v_i^2}{2} - \frac{v_i^2 y_i}{2 w_i} - \ell_i v_i \right]_{v_i = 0}^{\min \left\lbrace \frac{1}{2}, \frac{w_i (1-\ell_i)}{w_i + y_i} \right\rbrace} \\
	&= 2 \cdot \left[ (1-\ell_i) v_i - \frac{v_i^2}{2} \left( 1 + \frac{y_i}{w_i} \right) \right]_{v_i = 0}^{\min \left\lbrace \frac{1}{2}, \frac{w_i (1-\ell_i)}{w_i + y_i} \right\rbrace} \\
	&= 2 \cdot \left[ (1-\ell_i) v_i - \frac{v_i^2}{2} \frac{w_i + y_i}{w_i} \right]_{v_i = 0}^{\min \left\lbrace \frac{1}{2}, \frac{w_i (1-\ell_i)}{w_i + y_i} \right\rbrace} \\
	&= 2 \cdot \min \left\lbrace \frac{1-\ell_i}{2} - \frac{w_i + y_i}{8 w_i} , \enskip \frac{w_i (1-\ell_i)^2}{w_i + y_i} - \frac{w_i^2 (1-\ell_i)^2}{2 (w_i + y_i)^2} \frac{w_i + y_i}{w_i} \right\rbrace \\
	&= \min \left\lbrace \frac{3}{4} - \frac{y_i}{4 w_i} - \frac{\ell_i}{2} , \enskip \frac{w_i (1-\ell_i)^2}{w_i + y_i} \right\rbrace
\end{align*}


\end{document}








